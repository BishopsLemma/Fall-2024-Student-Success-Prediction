{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd418a7-e514-432a-95ff-49ffbf5bd753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data handling libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import machine learning libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1450b593-35ef-4b90-8432-a97dc6ba38d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STUDENT</th>\n",
       "      <th>GRADUATE</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>201</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>...</th>\n",
       "      <th>314</th>\n",
       "      <th>317</th>\n",
       "      <th>350</th>\n",
       "      <th>365</th>\n",
       "      <th>373</th>\n",
       "      <th>385</th>\n",
       "      <th>414</th>\n",
       "      <th>415</th>\n",
       "      <th>435</th>\n",
       "      <th>436</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STUDENT  GRADUATE  165  166  201  265  266  267  301  302  ...  314  317  \\\n",
       "0       51         1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1       75         1  1.5  3.0  4.0  4.0  0.0  5.5  6.5  0.0  ...  0.0  5.5   \n",
       "2       86         1  0.0  0.0  1.5  0.0  0.0  0.0  3.0  0.0  ...  4.0  0.5   \n",
       "3       94         1  0.0  0.0  0.5  0.0  0.0  0.0  2.0  3.0  ...  0.0  0.5   \n",
       "4      127         1  0.0  0.0  0.5  0.0  0.0  0.0  3.0  0.0  ...  0.0  0.5   \n",
       "\n",
       "   350  365  373  385  414  415  435  436  \n",
       "0  0.0  0.0  8.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  9.0  0.0  9.0  8.0  0.0  8.0  9.0  \n",
       "2  0.0  0.0  0.0  0.5  4.0  0.0  3.0  1.5  \n",
       "3  0.0  0.5  2.0  0.0  1.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  1.5  1.5  4.0  3.0  0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the math majors data set\n",
    "df = pd.read_csv('math_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21002d2a-ee78-4d4d-be53-7cfa2dfe3b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Students: 472\n",
      "Graduation Rate: 0.847457627118644\n"
     ]
    }
   ],
   "source": [
    "# Get some basic summary stats\n",
    "print('Total Number of Students:', len(df))\n",
    "print('Graduation Rate:', df['GRADUATE'].mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b176e9f7-d83e-4e9d-8c25-36bf127c024f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total enrollment for 165 is 100\n",
      "Total enrollment for 166 is 176\n",
      "Total enrollment for 201 is 333\n",
      "Total enrollment for 265 is 260\n",
      "Total enrollment for 266 is 81\n",
      "Total enrollment for 267 is 202\n",
      "Total enrollment for 301 is 320\n",
      "Total enrollment for 302 is 65\n",
      "Total enrollment for 304 is 89\n",
      "Total enrollment for 314 is 103\n",
      "Total enrollment for 317 is 352\n",
      "Total enrollment for 350 is 79\n",
      "Total enrollment for 365 is 64\n",
      "Total enrollment for 373 is 86\n",
      "Total enrollment for 385 is 67\n",
      "Total enrollment for 414 is 350\n",
      "Total enrollment for 415 is 79\n",
      "Total enrollment for 435 is 191\n",
      "Total enrollment for 436 is 183\n"
     ]
    }
   ],
   "source": [
    "# Total enrollment for each course\n",
    "courses = df.columns.tolist()[2:21]\n",
    "for x in courses:\n",
    "    print('Total enrollment for', x , 'is', np.count_nonzero(df[x]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968b4aab-886c-4733-bdc2-3ddf7ad29eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate for 165 is 0.95\n",
      "Success rate for 166 is 0.9431818181818182\n",
      "Success rate for 201 is 0.9579579579579579\n",
      "Success rate for 265 is 0.9538461538461539\n",
      "Success rate for 266 is 0.9629629629629629\n",
      "Success rate for 267 is 0.9405940594059405\n",
      "Success rate for 301 is 0.853125\n",
      "Success rate for 302 is 0.8769230769230769\n",
      "Success rate for 304 is 0.9325842696629213\n",
      "Success rate for 314 is 0.8737864077669902\n",
      "Success rate for 317 is 0.8948863636363636\n",
      "Success rate for 350 is 0.9493670886075949\n",
      "Success rate for 365 is 0.953125\n",
      "Success rate for 373 is 0.9186046511627907\n",
      "Success rate for 385 is 0.9552238805970149\n",
      "Success rate for 414 is 0.8428571428571429\n",
      "Success rate for 415 is 0.9367088607594937\n",
      "Success rate for 435 is 0.9057591623036649\n",
      "Success rate for 436 is 0.9453551912568307\n"
     ]
    }
   ],
   "source": [
    "# Success Rate for each course\n",
    "for x in courses:\n",
    "    print('Success rate for', x , 'is', df[x].gt(0).sum()/np.count_nonzero(df[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "860ec795-3307-442f-ac82-4339cb0ac944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train-test split\n",
    "X = df.drop(['STUDENT','GRADUATE'], axis=1)\n",
    "y = df['GRADUATE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42,\n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b4e5ff-a84e-48d9-b23a-e1f4595c292d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature importances for lda:\n",
      "266: 0.23278397147462782\n",
      "267: 0.23256187190048838\n",
      "385: 0.2049167902219841\n",
      "304: 0.20483146954413328\n",
      "373: 0.20381721913030998\n",
      "435: 0.19548502061972364\n",
      "317: 0.16995004326976781\n",
      "166: -0.15594594313309157\n",
      "201: -0.13909633304959698\n",
      "415: 0.11719067434806499\n",
      "165: -0.10393989079659291\n",
      "414: 0.09742914549272325\n",
      "302: 0.09559395604640789\n",
      "365: 0.07020751096312995\n",
      "350: -0.05967593302764393\n",
      "436: 0.04423954841521614\n",
      "301: 0.040572099861574874\n",
      "265: -0.034696537406879675\n",
      "314: 0.007929723666072\n",
      "\n",
      "Feature importances for log_reg:\n",
      "385: 16.895918441590137\n",
      "304: 0.6502300635548561\n",
      "373: 0.3979769242649966\n",
      "302: 0.38169385366253505\n",
      "435: 0.2826181967907263\n",
      "266: 0.262791758990796\n",
      "365: 0.24141545189222352\n",
      "317: 0.22956801175130784\n",
      "415: 0.16442946821407967\n",
      "267: 0.1166624912193127\n",
      "350: -0.10346704475192951\n",
      "414: 0.09888276402980312\n",
      "201: -0.09141409609621047\n",
      "301: 0.06662520274770442\n",
      "436: 0.056736394654530106\n",
      "314: -0.04794686271779804\n",
      "165: -0.04285931378911827\n",
      "265: 0.018869796043679395\n",
      "166: -0.004233291691900178\n",
      "\n",
      "Feature importances for svc_linear:\n",
      "385: 0.5812868906063208\n",
      "304: 0.19331998871478462\n",
      "373: 0.10733901547525468\n",
      "302: 0.09734040178425613\n",
      "435: 0.08605213017975229\n",
      "266: 0.08098873049645498\n",
      "365: 0.06723410841334361\n",
      "317: 0.06433500600107796\n",
      "415: 0.054522134409253104\n",
      "350: -0.034716334324555\n",
      "201: -0.033551461319214555\n",
      "414: 0.03207662134825229\n",
      "267: 0.029805271454604633\n",
      "301: 0.020191880729412224\n",
      "265: 0.01771743796024657\n",
      "436: 0.01743258129737464\n",
      "165: -0.016794350221516853\n",
      "314: -0.010889673016786937\n",
      "166: -0.0020899431435252138\n",
      "\n",
      "Feature importances for lda_poly:\n",
      "414: 19.97640751702284\n",
      "373: -7.843079962370222\n",
      "314: 7.086493265399062\n",
      "267: 6.645741693774983\n",
      "201: -4.825364689014837\n",
      "266: -3.554221559974346\n",
      "435: 2.9843430640078976\n",
      "304: 2.870569675791331\n",
      "436: 2.4973950670720435\n",
      "317: -2.3050201533478987\n",
      "415: 2.179083056222763\n",
      "350: 2.1435127379891616\n",
      "265: 2.078600916659078\n",
      "365: -1.8667945691231058\n",
      "385: 1.7663373948608454\n",
      "302: -0.749516876205663\n",
      "166: 0.47392295037184157\n",
      "301: -0.37525116783781554\n",
      "165: 5.028174135818732e-15\n",
      "\n",
      "Feature importances for log_reg_poly:\n",
      "165: 15.825192689860152\n",
      "415: 14.485037896975495\n",
      "314: 13.715857905724624\n",
      "436: 10.571201448551733\n",
      "265: -8.018269244861507\n",
      "301: 6.3293652972939\n",
      "266: -5.132965823613203\n",
      "435: -5.075861146294131\n",
      "414: 3.624714260463472\n",
      "373: -3.5447841664947655\n",
      "304: 2.9314071823488015\n",
      "317: 2.577519001108959\n",
      "267: -2.3619699406259085\n",
      "201: -2.2692189328481964\n",
      "166: 1.8238022508922629\n",
      "385: -1.7857945541050502\n",
      "302: 1.6992753055616057\n",
      "350: 0.7810299151238163\n",
      "365: -0.17155903869550837\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    # Putting linear decision boundary classifiers first\n",
    "    'lda' : LinearDiscriminantAnalysis(),\n",
    "    'log_reg' : LogisticRegression(penalty=None, max_iter= 100000),\n",
    "     'svc_linear' : LinearSVC(dual = 'auto'),\n",
    "\n",
    "    # Quadratic boundaries\n",
    "    'qda' : QuadraticDiscriminantAnalysis(),\n",
    "    'lda_poly' : Pipeline([('scale', StandardScaler()),('poly',PolynomialFeatures(2)),('lda', LinearDiscriminantAnalysis())]),\n",
    "    'log_reg_poly' : Pipeline([('scale', StandardScaler()),('poly',PolynomialFeatures(2)),('log_reg', LogisticRegression(penalty=None, max_iter= 100000))]),\n",
    "    'gnb' : GaussianNB(),\n",
    "\n",
    "    # Complex boundaries\n",
    "    'knn' : Pipeline([('scale', StandardScaler()),('knn', KNeighborsClassifier())]),   \n",
    "    'svc_rbf' : Pipeline([('scale', StandardScaler()),('svc',SVC(kernel= 'rbf'))])\n",
    "}\n",
    "importances = {}\n",
    "\n",
    "for model_name, model in classifiers.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    if hasattr(model, 'named_steps'):\n",
    "        # For pipelines, get the final step\n",
    "        final_model = model.named_steps[list(model.named_steps.keys())[-1]]\n",
    "    else:\n",
    "        final_model = model\n",
    "    \n",
    "    if hasattr(final_model, 'feature_importances_'):\n",
    "        importances[model_name] = final_model.feature_importances_\n",
    "    elif hasattr(final_model, 'coef_'):\n",
    "        importances[model_name] = final_model.coef_[0]  # For linear models\n",
    "        \n",
    "# Print feature importances or coefficients ordered by absolute value\n",
    "for model_name, importance in importances.items():\n",
    "    print(f\"\\nFeature importances for {model_name}:\")\n",
    "    sorted_importances = sorted(zip(X.columns, importance), key=lambda x: abs(x[1]), reverse=True)\n",
    "    for feature_name, value in sorted_importances:\n",
    "        print(f\"{feature_name}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9396b380-2f00-4a0a-9da1-59439381f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda: Mean -logloss = 0.8418, Std = 0.0210\n",
      "log_reg: Mean -logloss = 0.8869, Std = 0.0241\n",
      "svc_linear: Mean -logloss = 0.8643, Std = 0.0196\n",
      "qda: Mean -logloss = 0.9123, Std = 0.0356\n",
      "lda_poly: Mean -logloss = 0.7685, Std = 0.0444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\16313\\.conda\\envs\\erdos_fall_2024\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\16313\\.conda\\envs\\erdos_fall_2024\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_reg_poly: Mean -logloss = 0.9067, Std = 0.0148\n",
      "gnb: Mean -logloss = 0.7197, Std = 0.1832\n",
      "knn: Mean -logloss = 0.8927, Std = 0.0190\n",
      "svc_rbf: Mean -logloss = 0.9096, Std = 0.0329\n"
     ]
    }
   ],
   "source": [
    "cv_results = {}\n",
    "for model_name, model in classifiers.items():\n",
    "    scores = cross_val_score(model, \n",
    "                             X_train, \n",
    "                             y_train, \n",
    "                             cv=5,\n",
    "                             scoring='accuracy')\n",
    "    cv_results[model_name] = scores\n",
    "    print(f\"{model_name}: Mean -logloss = {scores.mean():.4f}, Std = {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7d991-5f4b-44f7-bce0-175cb7821264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
