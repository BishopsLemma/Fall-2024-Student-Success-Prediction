{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd418a7-e514-432a-95ff-49ffbf5bd753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data handling libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import machine learning libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1450b593-35ef-4b90-8432-a97dc6ba38d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STUDENT</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>201</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>304</th>\n",
       "      <th>...</th>\n",
       "      <th>317</th>\n",
       "      <th>350</th>\n",
       "      <th>365</th>\n",
       "      <th>373</th>\n",
       "      <th>385</th>\n",
       "      <th>414</th>\n",
       "      <th>415</th>\n",
       "      <th>435</th>\n",
       "      <th>436</th>\n",
       "      <th>GRADUATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STUDENT  165  166  201  265  266  267  301  302  304  ...  317  350  365  \\\n",
       "0       51  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1       75  2.0  3.0  4.0  4.0  0.0  5.0  6.0  0.0  0.0  ...  5.0  0.0  8.0   \n",
       "2       86  0.0  0.0  2.0  0.0  0.0  0.0  3.0  0.0  0.0  ...  1.0  0.0  0.0   \n",
       "3       94  0.0  0.0  1.0  0.0  0.0  0.0  2.0  3.0  0.0  ...  1.0  0.0  1.0   \n",
       "4      128  0.0  0.0  2.0  1.0  0.0  3.0  5.0  0.0  7.0  ...  3.0  4.0  0.0   \n",
       "\n",
       "   373  385  414  415  435  436  GRADUATE  \n",
       "0  7.0  0.0  0.0  0.0  0.0  0.0         1  \n",
       "1  0.0  8.0  7.0  0.0  7.0  8.0         1  \n",
       "2  0.0  1.0  4.0  0.0  3.0  2.0         1  \n",
       "3  2.0  0.0  2.0  0.0  0.0  0.0         1  \n",
       "4  0.0  0.0  8.0  0.0  7.0  0.0         1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the math majors data set\n",
    "df = pd.read_csv('lee_math_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21002d2a-ee78-4d4d-be53-7cfa2dfe3b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Students: 453\n",
      "Graduation Rate: 0.6114790286975718\n"
     ]
    }
   ],
   "source": [
    "# Get some basic summary stats\n",
    "print('Total Number of Students:', len(df))\n",
    "print('Graduation Rate:', df['GRADUATE'].mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b176e9f7-d83e-4e9d-8c25-36bf127c024f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total enrollment for 165 is 102\n",
      "Total enrollment for 166 is 175\n",
      "Total enrollment for 201 is 323\n",
      "Total enrollment for 265 is 250\n",
      "Total enrollment for 266 is 76\n",
      "Total enrollment for 267 is 194\n",
      "Total enrollment for 301 is 282\n",
      "Total enrollment for 302 is 56\n",
      "Total enrollment for 304 is 74\n",
      "Total enrollment for 314 is 91\n",
      "Total enrollment for 317 is 327\n",
      "Total enrollment for 350 is 68\n",
      "Total enrollment for 365 is 53\n",
      "Total enrollment for 373 is 74\n",
      "Total enrollment for 385 is 56\n",
      "Total enrollment for 414 is 299\n",
      "Total enrollment for 415 is 64\n",
      "Total enrollment for 435 is 170\n",
      "Total enrollment for 436 is 164\n"
     ]
    }
   ],
   "source": [
    "# Total enrollment for each course\n",
    "courses = df.columns.tolist()[1:20]\n",
    "for x in courses:\n",
    "    print('Total enrollment for', x , 'is', np.count_nonzero(df[x]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "968b4aab-886c-4733-bdc2-3ddf7ad29eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate for 165 is 0.9509803921568627\n",
      "Success rate for 166 is 0.9371428571428572\n",
      "Success rate for 201 is 0.9504643962848297\n",
      "Success rate for 265 is 0.948\n",
      "Success rate for 266 is 0.9605263157894737\n",
      "Success rate for 267 is 0.9484536082474226\n",
      "Success rate for 301 is 0.8617021276595744\n",
      "Success rate for 302 is 0.9107142857142857\n",
      "Success rate for 304 is 0.9594594594594594\n",
      "Success rate for 314 is 0.8901098901098901\n",
      "Success rate for 317 is 0.8990825688073395\n",
      "Success rate for 350 is 0.9558823529411765\n",
      "Success rate for 365 is 0.9622641509433962\n",
      "Success rate for 373 is 0.9324324324324325\n",
      "Success rate for 385 is 0.9642857142857143\n",
      "Success rate for 414 is 0.862876254180602\n",
      "Success rate for 415 is 0.921875\n",
      "Success rate for 435 is 0.9294117647058824\n",
      "Success rate for 436 is 0.9634146341463414\n"
     ]
    }
   ],
   "source": [
    "# Success Rate for each course\n",
    "for x in courses:\n",
    "    print('Success rate for', x , 'is', df[x].gt(0).sum()/np.count_nonzero(df[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "860ec795-3307-442f-ac82-4339cb0ac944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train-test split\n",
    "X = df.drop(['STUDENT','GRADUATE'], axis=1)\n",
    "y = df['GRADUATE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42,\n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00b4e5ff-a84e-48d9-b23a-e1f4595c292d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature importances for lda:\n",
      "304: 0.29480903463057434\n",
      "373: 0.19857899745733695\n",
      "166: -0.17591901600926874\n",
      "201: -0.17441130077460523\n",
      "302: 0.13346870535714114\n",
      "267: 0.1074490981675274\n",
      "317: 0.0885300002426222\n",
      "414: 0.08537006440453646\n",
      "435: 0.08462325750613356\n",
      "385: 0.06903843637349816\n",
      "436: 0.06901881859338377\n",
      "415: 0.06348876437789831\n",
      "266: 0.05263261493942331\n",
      "314: 0.04638814970008905\n",
      "265: -0.04258564927674052\n",
      "350: 0.0424487906004509\n",
      "165: -0.02415811430653786\n",
      "301: 0.01801503805113098\n",
      "365: -0.008387256955811185\n",
      "\n",
      "Feature importances for log_reg:\n",
      "304: 0.5313305218752841\n",
      "373: 0.24997778062293594\n",
      "302: 0.21629448127823378\n",
      "166: -0.1821276519466776\n",
      "201: -0.17300594479211837\n",
      "435: 0.10316461472353484\n",
      "385: 0.0906470114961204\n",
      "415: 0.0871929281117465\n",
      "267: 0.08497473313758966\n",
      "436: 0.08011148411975524\n",
      "317: 0.07795188176543578\n",
      "414: 0.07558692345574804\n",
      "265: -0.05281680957061115\n",
      "314: 0.052477396774416964\n",
      "350: 0.048398510075103006\n",
      "266: 0.039158136780787486\n",
      "365: 0.03632478567343711\n",
      "165: 0.016889828377409394\n",
      "301: 0.0101692102258383\n",
      "\n",
      "Feature importances for svc_linear:\n",
      "304: 0.16720073776684077\n",
      "373: 0.09001151865367457\n",
      "302: 0.071112236791642\n",
      "166: -0.06950287332819224\n",
      "201: -0.06720084646575773\n",
      "435: 0.03907437781693898\n",
      "415: 0.035951533672395695\n",
      "385: 0.03497946975607342\n",
      "267: 0.0347530050806337\n",
      "436: 0.03298344363031005\n",
      "414: 0.03169634187319239\n",
      "317: 0.028679465058328944\n",
      "365: 0.018739732581287628\n",
      "265: -0.017850889509655875\n",
      "266: 0.016159849785686888\n",
      "350: 0.015116105440433859\n",
      "314: 0.01506497750428406\n",
      "301: 0.005621697474696608\n",
      "165: -0.0028336007180199334\n",
      "\n",
      "Feature importances for lda_poly:\n",
      "385: 14.83183421260075\n",
      "436: 10.761826174311784\n",
      "314: 8.54326848564027\n",
      "373: -8.20538163361041\n",
      "415: 6.01467038591751\n",
      "350: -4.881290704501618\n",
      "414: -4.734600517584787\n",
      "317: 3.1113244166424794\n",
      "267: 2.956447532654592\n",
      "365: 2.123944111171112\n",
      "304: -1.8094874725329522\n",
      "301: -1.547462187507545\n",
      "166: -1.5439245018075871\n",
      "265: -1.4687615466598407\n",
      "201: 0.573781555558279\n",
      "266: -0.5052823013125564\n",
      "302: 0.4823178774389954\n",
      "435: -0.38430100979708703\n",
      "165: -5.12079805079374e-15\n",
      "\n",
      "Feature importances for log_reg_poly:\n",
      "314: 25.284047211441447\n",
      "165: 23.48486807898197\n",
      "415: 15.765359476125234\n",
      "436: 15.156206037356737\n",
      "201: -13.093076011461648\n",
      "317: 13.077081736777533\n",
      "435: -12.582110493315389\n",
      "414: -11.57346355481529\n",
      "373: -6.8442149591160355\n",
      "385: 6.584199744041325\n",
      "265: -6.181849095666185\n",
      "302: -6.143180385313752\n",
      "304: 6.128774127731348\n",
      "350: -5.580011776296112\n",
      "266: 4.404797355636574\n",
      "301: 3.3659547415355338\n",
      "166: -3.055898241094385\n",
      "267: 0.09412681031386551\n",
      "365: -0.020872140809103046\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    # Putting linear decision boundary classifiers first\n",
    "    'lda' : LinearDiscriminantAnalysis(),\n",
    "    'log_reg' : LogisticRegression(penalty=None, max_iter= 100000),\n",
    "     'svc_linear' : LinearSVC(dual = 'auto'),\n",
    "\n",
    "    # Quadratic boundaries\n",
    "    'qda' : QuadraticDiscriminantAnalysis(),\n",
    "    'lda_poly' : Pipeline([('scale', StandardScaler()),('poly',PolynomialFeatures(2)),('lda', LinearDiscriminantAnalysis())]),\n",
    "    'log_reg_poly' : Pipeline([('scale', StandardScaler()),('poly',PolynomialFeatures(2)),('log_reg', LogisticRegression(penalty=None, max_iter= 100000))]),\n",
    "    'gnb' : GaussianNB(),\n",
    "\n",
    "    # Complex boundaries\n",
    "    'knn' : Pipeline([('scale', StandardScaler()),('knn', KNeighborsClassifier())]),   \n",
    "    'svc_rbf' : Pipeline([('scale', StandardScaler()),('svc',SVC(kernel= 'rbf'))])\n",
    "}\n",
    "importances = {}\n",
    "\n",
    "for model_name, model in classifiers.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    if hasattr(model, 'named_steps'):\n",
    "        # For pipelines, get the final step\n",
    "        final_model = model.named_steps[list(model.named_steps.keys())[-1]]\n",
    "    else:\n",
    "        final_model = model\n",
    "    \n",
    "    if hasattr(final_model, 'feature_importances_'):\n",
    "        importances[model_name] = final_model.feature_importances_\n",
    "    elif hasattr(final_model, 'coef_'):\n",
    "        importances[model_name] = final_model.coef_[0]  # For linear models\n",
    "        \n",
    "# Print feature importances or coefficients ordered by absolute value\n",
    "for model_name, importance in importances.items():\n",
    "    print(f\"\\nFeature importances for {model_name}:\")\n",
    "    sorted_importances = sorted(zip(X.columns, importance), key=lambda x: abs(x[1]), reverse=True)\n",
    "    for feature_name, value in sorted_importances:\n",
    "        print(f\"{feature_name}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9396b380-2f00-4a0a-9da1-59439381f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda: Mean -logloss = 0.7581, Std = 0.0514\n",
      "log_reg: Mean -logloss = 0.7493, Std = 0.0549\n",
      "svc_linear: Mean -logloss = 0.7552, Std = 0.0496\n",
      "qda: Mean -logloss = 0.7491, Std = 0.0646\n",
      "lda_poly: Mean -logloss = 0.6873, Std = 0.0521\n",
      "log_reg_poly: Mean -logloss = 0.7787, Std = 0.0467\n",
      "gnb: Mean -logloss = 0.7019, Std = 0.0463\n",
      "knn: Mean -logloss = 0.7877, Std = 0.0340\n",
      "svc_rbf: Mean -logloss = 0.8023, Std = 0.0392\n",
      "lda: Mean -logloss = 0.7581, Std = 0.0514\n",
      "log_reg: Mean -logloss = 0.7493, Std = 0.0549\n",
      "svc_linear: Mean -logloss = 0.7552, Std = 0.0496\n",
      "qda: Mean -logloss = 0.7491, Std = 0.0646\n",
      "lda_poly: Mean -logloss = 0.6873, Std = 0.0521\n",
      "log_reg_poly: Mean -logloss = 0.7787, Std = 0.0467\n",
      "gnb: Mean -logloss = 0.7019, Std = 0.0463\n",
      "knn: Mean -logloss = 0.7877, Std = 0.0340\n",
      "svc_rbf: Mean -logloss = 0.8023, Std = 0.0392\n"
     ]
    }
   ],
   "source": [
    "cv_results = {}\n",
    "for model_name, model in classifiers.items():\n",
    "    scores = cross_val_score(model, \n",
    "                             X_train, \n",
    "                             y_train, \n",
    "                             cv=5,\n",
    "                             scoring='accuracy')\n",
    "    cv_results[model_name] = scores\n",
    "    print(f\"{model_name}: Mean -logloss = {scores.mean():.4f}, Std = {scores.std():.4f}\")\n",
    "\n",
    "# Print the cross-validation results\n",
    "for model_name, scores in cv_results.items():\n",
    "    print(f\"{model_name}: Mean -logloss = {scores.mean():.4f}, Std = {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7d991-5f4b-44f7-bce0-175cb7821264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
