{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c961ebb9-9cd7-46f5-ac8a-de15ae92f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D Larue, 10/29/24\n",
    "# Which courses predict graduation\n",
    "\n",
    "# Data Processing\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bd8206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in cleaned data\n",
    "grades = pd.read_csv('newdata.csv')\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = grades.drop(['STUDENT','ENTRY_CCYY','SEM_CCYY.1','DEG_CD','GRAD_TIME'], axis=1)\n",
    "y = grades['DEG_CD']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=y)\n",
    "\n",
    "fn = grades.columns.tolist()[5:]\n",
    "cn=['not graduated','graduated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7400d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy RandomForestClassifier: 0.6232106339468303\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42,\n",
    "                            class_weight='balanced_subsample',\n",
    "                            bootstrap=True,\n",
    "                            max_samples=0.7\n",
    "                            )\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy RandomForestClassifier:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a5fad07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy DecisionTreeClassifier: 0.7341513292433538\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth = 1, \n",
    "                            #  random_state = 42, \n",
    "                             criterion = 'gini') # gini entropy\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy DecisionTreeClassifier:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.7341513292433538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fea89729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "                feature  importance\n",
      "5   INTRO TO PROBABILTY    0.087241\n",
      "12    PREP FOR CALCULUS    0.082955\n",
      "2            CALCULUS I    0.078074\n",
      "1           CALCULUS II    0.069869\n",
      "3   MATRCES&LINEAR ALGB    0.066392\n",
      "0          CALCULUS III    0.063532\n",
      "4       COLLEGE ALGEBRA    0.052776\n",
      "11  DISC MATH BUS&SOC S    0.040773\n",
      "8   THRY LINEAR ALGEBRA    0.039834\n",
      "15    ELEM DIFF EQUATNS    0.038798\n",
      "25   SURVEY OF CALCULUS    0.036778\n",
      "9       INTRO TO PROOFS    0.031743\n",
      "7    DIFF EQ & TRANSFMS    0.031600\n",
      "13  INTRO TO MATH IDEAS    0.027616\n",
      "20           ANALYSIS I    0.026790\n",
      "30   BUS & SOC SCI CALC    0.020506\n",
      "19   ABSTRACT ALGEBRA I    0.020056\n",
      "14  ORIENTATION IN MATH    0.019808\n",
      "24    UNDERGRAD SEMINAR    0.017793\n",
      "6   INTR PART DIFF EQUA    0.017405\n",
      "10  HIGH SCHOOL ALGEBRA    0.017388\n",
      "37  LIFE SCI CALC&MDL I    0.015063\n",
      "17  INTR THY PROBAB&S I    0.013509\n",
      "40   APPLD TRIGONOMETRY    0.009527\n",
      "18  INTRO PROBAB&MATRIC    0.009165\n",
      "26         GRAPH THEORY    0.008123\n",
      "21           GEOMETRY I    0.006407\n",
      "35     DISCOVERING MATH    0.005199\n",
      "23          GEOMETRY II    0.005125\n",
      "22    COMPLEX VARIABLES    0.004968\n",
      "31        NUMBER THEORY    0.004938\n",
      "33        COMBINATORICS    0.004400\n",
      "16  INTR SCIENTF CMPTNG    0.004191\n",
      "28       SPECIAL TOPICS    0.004013\n",
      "34  INVESTM&CREDIT MATH    0.003011\n",
      "38          ANALYSIS II    0.002905\n",
      "29   ABSTRCT ALGEBRA II    0.002429\n",
      "32    INDEPENDENT STUDY    0.002125\n",
      "41  INTR THY PR&STAT II    0.001698\n",
      "39  TEACH SEC SCHL MATH    0.001645\n",
      "42             TOPOLOGY    0.001560\n",
      "36  NUMRC MTHDS DIFF EQ    0.001147\n",
      "27  UNIV MATH TCH SECDY    0.001128\n"
     ]
    }
   ],
   "source": [
    "#print feature importance from rf\n",
    "# Get feature importances from the random forest classifier\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a dataframe of features and their importance scores\n",
    "feature_importance = pd.DataFrame({'feature': fn, 'importance': importances})\n",
    "\n",
    "# Sort by importance descending\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0173a883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LogisticRegression: 0.6114519427402862\n"
     ]
    }
   ],
   "source": [
    "#instantiate the logistic regression class\n",
    "lr = LogisticRegression(random_state=42, \n",
    "                        class_weight='balanced')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy LogisticRegression:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a47fa705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Feature Importances (by coefficient magnitude):\n",
      "                feature  coefficient\n",
      "39  TEACH SEC SCHL MATH     1.180257\n",
      "30   BUS & SOC SCI CALC     0.885704\n",
      "24    UNDERGRAD SEMINAR     0.750702\n",
      "37  LIFE SCI CALC&MDL I     0.743017\n",
      "18  INTRO PROBAB&MATRIC     0.714024\n",
      "36  NUMRC MTHDS DIFF EQ     0.618842\n",
      "25   SURVEY OF CALCULUS     0.613351\n",
      "5   INTRO TO PROBABILTY     0.609754\n",
      "13  INTRO TO MATH IDEAS     0.488674\n",
      "8   THRY LINEAR ALGEBRA     0.471956\n",
      "15    ELEM DIFF EQUATNS     0.449634\n",
      "38          ANALYSIS II     0.422136\n",
      "17  INTR THY PROBAB&S I     0.372700\n",
      "11  DISC MATH BUS&SOC S     0.371436\n",
      "3   MATRCES&LINEAR ALGB     0.360283\n",
      "35     DISCOVERING MATH     0.304468\n",
      "14  ORIENTATION IN MATH     0.220100\n",
      "4       COLLEGE ALGEBRA     0.214009\n",
      "9       INTRO TO PROOFS     0.182393\n",
      "42             TOPOLOGY     0.175226\n",
      "20           ANALYSIS I     0.170897\n",
      "32    INDEPENDENT STUDY     0.162395\n",
      "16  INTR SCIENTF CMPTNG     0.157137\n",
      "6   INTR PART DIFF EQUA     0.156901\n",
      "33        COMBINATORICS     0.146305\n",
      "34  INVESTM&CREDIT MATH     0.135335\n",
      "23          GEOMETRY II     0.133680\n",
      "0          CALCULUS III     0.132521\n",
      "10  HIGH SCHOOL ALGEBRA     0.131677\n",
      "2            CALCULUS I     0.126719\n",
      "28       SPECIAL TOPICS     0.123664\n",
      "31        NUMBER THEORY     0.117924\n",
      "1           CALCULUS II     0.116086\n",
      "19   ABSTRACT ALGEBRA I     0.084989\n",
      "21           GEOMETRY I     0.080596\n",
      "29   ABSTRCT ALGEBRA II     0.070640\n",
      "27  UNIV MATH TCH SECDY     0.068553\n",
      "12    PREP FOR CALCULUS     0.039145\n",
      "22    COMPLEX VARIABLES     0.033119\n",
      "26         GRAPH THEORY     0.033059\n",
      "41  INTR THY PR&STAT II     0.029748\n",
      "40   APPLD TRIGONOMETRY     0.002753\n",
      "7    DIFF EQ & TRANSFMS     0.001383\n"
     ]
    }
   ],
   "source": [
    "# Get coefficients from logistic regression\n",
    "coef = lr.coef_[0]\n",
    "\n",
    "# Create a dataframe of features and their coefficient values\n",
    "lr_importance = pd.DataFrame({'feature': fn, 'coefficient': abs(coef)})\n",
    "\n",
    "# Sort by absolute coefficient value descending \n",
    "lr_importance = lr_importance.sort_values('coefficient', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "print(\"Logistic Regression Feature Importances (by coefficient magnitude):\")\n",
    "print(lr_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b81bde33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of the data\n",
    "X_copy = grades.drop(['STUDENT','ENTRY_CCYY','SEM_CCYY.1','DEG_CD','GRAD_TIME'], axis=1)\n",
    "y_copy = grades['DEG_CD']\n",
    "\n",
    "# In all columns of X_copy, replace each 1 with 0, and replace each 2 and 3 with 1\n",
    "X_copy = X_copy.replace({1: 0, 2: 1, 3: 1})\n",
    "#re-do the train-test split using X_copy and y_copy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_copy, y_copy, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=y_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f9d3899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy RandomForestClassifier (modified): 0.6119631901840491\n"
     ]
    }
   ],
   "source": [
    "# create new random forest model, fit to the data, predict, and print accuracy\n",
    "rf = RandomForestClassifier(random_state=42,\n",
    "                            class_weight='balanced_subsample',\n",
    "                            bootstrap=True,\n",
    "                            max_samples=0.7\n",
    "                            )\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy RandomForestClassifier (modified):\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4b565a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy DecisionTreeClassifier (modified): 0.7341513292433538\n"
     ]
    }
   ],
   "source": [
    "# create new decision tree model, fit to the data, predict, and print accuracy\n",
    "clf = DecisionTreeClassifier(max_depth = 1, \n",
    "                             random_state = 42, \n",
    "                             criterion = 'gini') # gini entropy\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy DecisionTreeClassifier (modified):\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9796b011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LogisticRegression: 0.6053169734151329\n"
     ]
    }
   ],
   "source": [
    "# create new logistic regression model, fit to the data, predict, and print accuracy\n",
    "lr = LogisticRegression(random_state=42, \n",
    "                        class_weight='balanced')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy LogisticRegression:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee7ef468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importances (modified):\n",
      "                feature  importance\n",
      "5   INTRO TO PROBABILTY    0.118500\n",
      "3   MATRCES&LINEAR ALGB    0.063982\n",
      "2            CALCULUS I    0.056811\n",
      "11  DISC MATH BUS&SOC S    0.049982\n",
      "4       COLLEGE ALGEBRA    0.047125\n",
      "1           CALCULUS II    0.046047\n",
      "0          CALCULUS III    0.045690\n",
      "25   SURVEY OF CALCULUS    0.042232\n",
      "8   THRY LINEAR ALGEBRA    0.042075\n",
      "13  INTRO TO MATH IDEAS    0.039568\n",
      "12    PREP FOR CALCULUS    0.039258\n",
      "15    ELEM DIFF EQUATNS    0.039196\n",
      "9       INTRO TO PROOFS    0.031360\n",
      "24    UNDERGRAD SEMINAR    0.030138\n",
      "7    DIFF EQ & TRANSFMS    0.028522\n",
      "20           ANALYSIS I    0.027979\n",
      "30   BUS & SOC SCI CALC    0.024930\n",
      "14  ORIENTATION IN MATH    0.023921\n",
      "6   INTR PART DIFF EQUA    0.021295\n",
      "19   ABSTRACT ALGEBRA I    0.020862\n",
      "17  INTR THY PROBAB&S I    0.020090\n",
      "37  LIFE SCI CALC&MDL I    0.019489\n",
      "10  HIGH SCHOOL ALGEBRA    0.015508\n",
      "18  INTRO PROBAB&MATRIC    0.013279\n",
      "26         GRAPH THEORY    0.009278\n",
      "23          GEOMETRY II    0.007942\n",
      "40   APPLD TRIGONOMETRY    0.007192\n",
      "35     DISCOVERING MATH    0.007021\n",
      "33        COMBINATORICS    0.006891\n",
      "21           GEOMETRY I    0.006805\n",
      "31        NUMBER THEORY    0.006691\n",
      "16  INTR SCIENTF CMPTNG    0.005717\n",
      "28       SPECIAL TOPICS    0.005596\n",
      "22    COMPLEX VARIABLES    0.005435\n",
      "38          ANALYSIS II    0.004064\n",
      "34  INVESTM&CREDIT MATH    0.003792\n",
      "39  TEACH SEC SCHL MATH    0.003015\n",
      "32    INDEPENDENT STUDY    0.003010\n",
      "41  INTR THY PR&STAT II    0.002712\n",
      "27  UNIV MATH TCH SECDY    0.002239\n",
      "42             TOPOLOGY    0.001848\n",
      "29   ABSTRCT ALGEBRA II    0.001622\n",
      "36  NUMRC MTHDS DIFF EQ    0.001291\n",
      "Logistic Regression Feature Importances (modified):\n",
      "                feature  coefficient\n",
      "30   BUS & SOC SCI CALC     2.083101\n",
      "37  LIFE SCI CALC&MDL I     1.979647\n",
      "24    UNDERGRAD SEMINAR     1.907138\n",
      "18  INTRO PROBAB&MATRIC     1.757283\n",
      "5   INTRO TO PROBABILTY     1.662537\n",
      "25   SURVEY OF CALCULUS     1.622060\n",
      "39  TEACH SEC SCHL MATH     1.606142\n",
      "13  INTRO TO MATH IDEAS     1.310583\n",
      "15    ELEM DIFF EQUATNS     1.223077\n",
      "8   THRY LINEAR ALGEBRA     1.219588\n",
      "3   MATRCES&LINEAR ALGB     0.995926\n",
      "11  DISC MATH BUS&SOC S     0.986856\n",
      "17  INTR THY PROBAB&S I     0.973769\n",
      "38          ANALYSIS II     0.954677\n",
      "36  NUMRC MTHDS DIFF EQ     0.839482\n",
      "35     DISCOVERING MATH     0.691790\n",
      "4       COLLEGE ALGEBRA     0.585223\n",
      "16  INTR SCIENTF CMPTNG     0.574037\n",
      "33        COMBINATORICS     0.572038\n",
      "6   INTR PART DIFF EQUA     0.525092\n",
      "23          GEOMETRY II     0.522561\n",
      "20           ANALYSIS I     0.437170\n",
      "14  ORIENTATION IN MATH     0.422108\n",
      "28       SPECIAL TOPICS     0.418337\n",
      "29   ABSTRCT ALGEBRA II     0.417346\n",
      "9       INTRO TO PROOFS     0.394373\n",
      "10  HIGH SCHOOL ALGEBRA     0.330292\n",
      "1           CALCULUS II     0.325835\n",
      "32    INDEPENDENT STUDY     0.318000\n",
      "34  INVESTM&CREDIT MATH     0.307625\n",
      "0          CALCULUS III     0.307281\n",
      "2            CALCULUS I     0.306055\n",
      "31        NUMBER THEORY     0.291521\n",
      "42             TOPOLOGY     0.280308\n",
      "19   ABSTRACT ALGEBRA I     0.162558\n",
      "41  INTR THY PR&STAT II     0.156651\n",
      "40   APPLD TRIGONOMETRY     0.147214\n",
      "26         GRAPH THEORY     0.110085\n",
      "12    PREP FOR CALCULUS     0.103852\n",
      "21           GEOMETRY I     0.068287\n",
      "22    COMPLEX VARIABLES     0.053147\n",
      "27  UNIV MATH TCH SECDY     0.047677\n",
      "7    DIFF EQ & TRANSFMS     0.014621\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance from ranodm forest classifier and loistic regression\n",
    "importances = rf.feature_importances_\n",
    "rf_feature_importance = pd.DataFrame({'feature': fn, 'importance': importances})\n",
    "rf_feature_importance = rf_feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "coef = lr.coef_[0]\n",
    "lr_importance = pd.DataFrame({'feature': fn, 'coefficient': abs(coef)})\n",
    "lr_importance = lr_importance.sort_values('coefficient', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "print(\"Random Forest Feature Importances (modified):\")\n",
    "print(rf_feature_importance)\n",
    "print(\"Logistic Regression Feature Importances (modified):\")\n",
    "print(lr_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c445408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
