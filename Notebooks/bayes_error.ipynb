{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes error rate\n",
    "In this notebook, we provide an explanation for the low accuracy of our binary classification models. In a nutshell, the problem lies within our (final, cleaned) dataset-- there is an *intrinsic* upper bound on the accuracy we could have hoped to achieve, and this upper bound is not much higher than the accuracy we were actually able to obtain (so, in other words, our models actually performed fairly well relative to the theoretical best accuracy). The following toy example already serves to illustrate the key idea.\n",
    "\n",
    "### A toy example\n",
    "Suppose we have a binary classification problem, wherein we have a dataset with some features $X$ and a binary target variable $Y$. Suppose the dataset contains exactly two observations, both of which have identical features $X$, but $Y=1$ for the first observation and $Y=0$ for the second observation. Then, *any classifier* we could train would make the same predictions for the two observations, becuase they are completely indistinguishable by the features used to train the classifier. Thus, whether or not this classifier predicts $1$ or $0$, we are guaranteed to have an error rate of $50\\%$!\n",
    "\n",
    "### Generalizing the example\n",
    "This guaranteed error rate generalizes naturally to binary classification problems involving larger datasets (and discrete features). Namely:\n",
    "- Suppose we have a dataset with features $X$ (treating multiple scalar-valued features as a single vector-valued feature) and binary target $Y$. \n",
    "- Suppose there is some value of $X$ (i.e. a row vector) which arises as the set of features for a group of $m$ observations. \n",
    "- Within this group, suppose $m_1$ observations belong to class $Y=1$, and $m_0$ belong to $Y=0$ (so $m = m_1 + m_0$). \n",
    "\n",
    "Then, by the same logic as above, *any* binary classifier trained on the dataset would make the same, constant prediction for all $m$ members in the group. In fact, if the classifier is sensibly trained, it would predict the majority class within the group, leading to misclassifications for all memebers in the minority class within the group. Thus, in the best case scenario, out of $m$ observations, $\\min(m_0,m_1)$ would be misclassifications, so this group would contribute a (theoretically unavoidable) error rate of\n",
    "\\begin{equation*} \\dfrac{ \\min(m_0,m_1) }{\\# \\{\\textup{all observations} \\}}. \\end{equation*}\n",
    "This idea (made rigorous) leads to the *Bayes Error Rate* for a binary classification problem (by which mean the problem of predicting $Y$ from $X$ for a *given* dataset)-- it is the least possible error that can be achieved by *any* classifier for the given problem.\n",
    "\n",
    "### Bayes Classifier\n",
    "The Bayes classifier $C^{\\textup{Bayes}}$ is the most natural binary classifier that can be conceived of for a given binary classification problem. In a nutshell, given an observation $X=x$, the classifier simply groups together all observations with the same value of $X$ (i.e. identical feature rows in the dataset) and predicts $Y$ according to the majority class within the group. Note: grouping by $X=x$ and computing the probability of each class amounts to computing the conditional probabilities $Pr(Y=1|X=x)$ and $Pr(Y=0|X=x)$. Thus, for each observation in the group corresponding to $X=x$, the Bayes Classifier predicts as follows:\n",
    "\\begin{equation*} C^{\\textup{Bayes}}(x) \\coloneqq \\max \\big(Pr(Y=1|X=x), Pr(Y=0|X=x) \\big). \\end{equation*}\n",
    "Why do we bring up the Bayes Classifier? As might already be apparent from its design and naturality, the Bayes Classifier is the \"best possible\" binary classifier in the sense that the error rate equals the theoretical minimum, i.e. the Bayes Error Rate. \n",
    "\n",
    "### Computing the Bayes Classifier\n",
    "One expects or assumes that the dataset contains a (more or less) representative sample of the distribution of $X$, so  one is typically not interested in predicting $Y$ based on any specific value of $X$, but rather, on the whole range of possible values of $X$. \n",
    "\n",
    "Thus, in practice, directly computing the Bayes Classifier as defined may not be very useful, and instead, one is interested in *estimating* the Bayes Classifier, which amounts to estimating the prior distribution of $Y$ given that of $X$. \n",
    "\n",
    "Nevertheless, directly computing the Bayes Classifier will at least yield a *strict lower bound* on the \"true\" Bayes Error Rate (i.e. the error rate for the \"true\" distribution of $X$ and $Y$). Indeed, there will likely be lots of \"singleton\" observations which have a unique vector of feature values (especially if $X$ has continuous features). These singletons don't contribute to the error of the Bayes Classifier because there is no minority class to be misclassified within the singleton. By contrast, any practicable classifier trained on the distribution of $X$ will likely accumulate error on these observations (unless it is dangerously overfit!) \n",
    "\n",
    "### Bayes Classifier for our dataset\n",
    "That said, our dataset is quite small (around 9000 observations), so even though our feature-vectors could potentially have millions of distinct values (specifically, $20$ to the power of the number of courses), there are at most 9000 of them! So, let's go ahead and compute the Bayes Classifier (by hand) for our dataset as follows:\n",
    "1. First, we group together out dataframe by the unique values of the vector of courses (this is out $X$).\n",
    "2. For each group, we add columns:\n",
    "    - `COUNT(X)`: the size of the group\n",
    "    - `Pr(X)`: the probability of the observation occuring, i.e. `COUNT(X)` divided by total size of the dataset.\n",
    "    - `Pr(Y=1|X)`: Probability of the `Y=1` class within the group.\n",
    "    - `ERROR(Y|X)`: Unavoidable (conditional) error introduced when predicting on the group, equal to $\\min \\big( Pr(Y=1|X), Pr(Y=0|X) \\big)$.\n",
    "    - `ERROR(Y|X) * Pr(X)`: Unavoidable (absolute) error introduced to the whole dataset because of the group.\n",
    "    - `CUMULATIVE_ERROR`: A cumulative sum of the above errors as we go down the dataset (after sorting in descending order of the absolute error).\n",
    "    - The final value of `CUMULATIVE_ERROR` is nothing but the expected value of the conditional errors (taken over the distribution of $X$).\n",
    "3. Finally, we split the dataframe into two parts, the first having groups of size greater than one (so there is at all some potential for misclassification), and the second consisting of singleton groups (which don't contribute to error of the Bayes Classifier, but are likely to induce errors on other binary classifiers trained on the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add root directory to Python path\n",
    "root_dir = Path.cwd().parent  # Go up one level from Notebooks folder\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.append(str(root_dir))\n",
    "\n",
    "# Now import from Source Code directory\n",
    "sys.path.append(str(root_dir / 'Source Code'))\n",
    "from modeller import *\n",
    "\n",
    "#import the dataset\n",
    "df = pd.read_csv('../Data/Datasets/dataset_engineered.csv')\n",
    "\n",
    "#automatically reload all modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#load course dict\n",
    "with open('../Data/Dictionaries/crse_dict.json') as f:\n",
    "    crse_dict = json.load(f)\n",
    "courses = list(crse_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df, singletons_df = get_bayes_error(df,courses,save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the top 10 rows of the grouped dataset to see the groups contributing the largest error to our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>265</th>\n",
       "      <th>143</th>\n",
       "      <th>140</th>\n",
       "      <th>104</th>\n",
       "      <th>150</th>\n",
       "      <th>207</th>\n",
       "      <th>201</th>\n",
       "      <th>317</th>\n",
       "      <th>...</th>\n",
       "      <th>495</th>\n",
       "      <th>314</th>\n",
       "      <th>500</th>\n",
       "      <th>304</th>\n",
       "      <th>COUNT(X)</th>\n",
       "      <th>Pr(X)</th>\n",
       "      <th>Pr(Y=1|X)</th>\n",
       "      <th>ERROR(Y|X)</th>\n",
       "      <th>ERROR(Y|X) * Pr(X)</th>\n",
       "      <th>CUMULATIVE_ERROR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324</td>\n",
       "      <td>0.035290</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.016665</td>\n",
       "      <td>0.016665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>344</td>\n",
       "      <td>0.037469</td>\n",
       "      <td>0.412791</td>\n",
       "      <td>0.412791</td>\n",
       "      <td>0.015467</td>\n",
       "      <td>0.032132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214</td>\n",
       "      <td>0.023309</td>\n",
       "      <td>0.602804</td>\n",
       "      <td>0.397196</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>0.041390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189</td>\n",
       "      <td>0.020586</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.008496</td>\n",
       "      <td>0.049886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177</td>\n",
       "      <td>0.019279</td>\n",
       "      <td>0.604520</td>\n",
       "      <td>0.395480</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.057510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>0.390411</td>\n",
       "      <td>0.390411</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.063719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159</td>\n",
       "      <td>0.017318</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.069491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>0.643836</td>\n",
       "      <td>0.356164</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.075155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136</td>\n",
       "      <td>0.014813</td>\n",
       "      <td>0.683824</td>\n",
       "      <td>0.316176</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.079839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95</td>\n",
       "      <td>0.010347</td>\n",
       "      <td>0.442105</td>\n",
       "      <td>0.442105</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.084413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   165  166  265  143  140  104  150  207  201  317  ...  495  314  500  304  \\\n",
       "0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "5  1.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "6  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "8  0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "9  2.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   COUNT(X)     Pr(X)  Pr(Y=1|X)  ERROR(Y|X)  ERROR(Y|X) * Pr(X)  \\\n",
       "0       324  0.035290   0.472222    0.472222            0.016665   \n",
       "1       344  0.037469   0.412791    0.412791            0.015467   \n",
       "2       214  0.023309   0.602804    0.397196            0.009258   \n",
       "3       189  0.020586   0.412698    0.412698            0.008496   \n",
       "4       177  0.019279   0.604520    0.395480            0.007624   \n",
       "5       146  0.015902   0.390411    0.390411            0.006208   \n",
       "6       159  0.017318   0.333333    0.333333            0.005773   \n",
       "7       146  0.015902   0.643836    0.356164            0.005664   \n",
       "8       136  0.014813   0.683824    0.316176            0.004684   \n",
       "9        95  0.010347   0.442105    0.442105            0.004575   \n",
       "\n",
       "   CUMULATIVE_ERROR  \n",
       "0          0.016665  \n",
       "1          0.032132  \n",
       "2          0.041390  \n",
       "3          0.049886  \n",
       "4          0.057510  \n",
       "5          0.063719  \n",
       "6          0.069491  \n",
       "7          0.075155  \n",
       "8          0.079839  \n",
       "9          0.084413  \n",
       "\n",
       "[10 rows x 34 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 578 groups of feature values of size greater than 1.\n",
      "There are 2002 singleton groups of feature values.\n",
      "Total number of groups: 2580\n",
      "Lower bound on Bayes Error Rate: 0.2528047053697844\n",
      "Error contributed by 0.7819409650364885 of the whole dataset.\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(grouped_df)} groups of feature values of size greater than 1.')\n",
    "print(f'There are {len(singletons_df)} singleton groups of feature values.')\n",
    "print(f'Total number of groups: {len(grouped_df)+len(singletons_df)}')\n",
    "print(f'Lower bound on Bayes Error Rate: {grouped_df.iloc[-1][\"CUMULATIVE_ERROR\"]}')\n",
    "grouped_prob = grouped_df['Pr(X)'].sum()\n",
    "print(f'Error contributed by {grouped_prob} of the whole dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we have it! Our original dataset of approx. 9000 observations actually only contains 2580 distinct observations. \n",
    "\n",
    "Of these, 2002 are singleton observations, from which our computations don't reveal any intrinsic error.\n",
    "\n",
    "The remaining 578 groups of observations account for a 25.2% error rate! \n",
    "\n",
    "Thus, our binary classifiers incurred only 10% more error than the theoretical least possible error (which itself must be a gross under-estimate given that 2002 observations are not contributing).\n",
    "\n",
    "Thus, relative to this minimum forced error, it is reasonable to conclude that our models performed reasonably well, and the bulk of the error is caused by the insufficient ability of the features (courses) to separate the classes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>265</th>\n",
       "      <th>143</th>\n",
       "      <th>140</th>\n",
       "      <th>104</th>\n",
       "      <th>150</th>\n",
       "      <th>207</th>\n",
       "      <th>201</th>\n",
       "      <th>317</th>\n",
       "      <th>...</th>\n",
       "      <th>495</th>\n",
       "      <th>314</th>\n",
       "      <th>500</th>\n",
       "      <th>304</th>\n",
       "      <th>COUNT(X)</th>\n",
       "      <th>Pr(X)</th>\n",
       "      <th>Pr(Y|X)</th>\n",
       "      <th>ERROR(Y|X)</th>\n",
       "      <th>ERROR(Y|X) * Pr(X)</th>\n",
       "      <th>CUMULATIVE_ERROR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324</td>\n",
       "      <td>0.035290</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.016665</td>\n",
       "      <td>0.016665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>344</td>\n",
       "      <td>0.037469</td>\n",
       "      <td>0.412791</td>\n",
       "      <td>0.412791</td>\n",
       "      <td>0.015467</td>\n",
       "      <td>0.032132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214</td>\n",
       "      <td>0.023309</td>\n",
       "      <td>0.602804</td>\n",
       "      <td>0.397196</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>0.041390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189</td>\n",
       "      <td>0.020586</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.008496</td>\n",
       "      <td>0.049886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177</td>\n",
       "      <td>0.019279</td>\n",
       "      <td>0.604520</td>\n",
       "      <td>0.395480</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.057510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>0.390411</td>\n",
       "      <td>0.390411</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.063719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159</td>\n",
       "      <td>0.017318</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.069491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146</td>\n",
       "      <td>0.015902</td>\n",
       "      <td>0.643836</td>\n",
       "      <td>0.356164</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.075155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136</td>\n",
       "      <td>0.014813</td>\n",
       "      <td>0.683824</td>\n",
       "      <td>0.316176</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.079839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95</td>\n",
       "      <td>0.010347</td>\n",
       "      <td>0.442105</td>\n",
       "      <td>0.442105</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.084413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.088770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96</td>\n",
       "      <td>0.010456</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>0.092909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84</td>\n",
       "      <td>0.009149</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>0.097048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116</td>\n",
       "      <td>0.012635</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.003703</td>\n",
       "      <td>0.100752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>0.009803</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>0.104237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    165  166  265  143  140  104  150  207  201  317  ...  495  314  500  304  \\\n",
       "0   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "5   1.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "6   2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "8   0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "9   2.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "10  0.0  1.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "11  0.0  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "13  0.0  0.0  0.0  0.0  0.0  3.5  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "14 -1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    COUNT(X)     Pr(X)   Pr(Y|X)  ERROR(Y|X)  ERROR(Y|X) * Pr(X)  \\\n",
       "0        324  0.035290  0.472222    0.472222            0.016665   \n",
       "1        344  0.037469  0.412791    0.412791            0.015467   \n",
       "2        214  0.023309  0.602804    0.397196            0.009258   \n",
       "3        189  0.020586  0.412698    0.412698            0.008496   \n",
       "4        177  0.019279  0.604520    0.395480            0.007624   \n",
       "5        146  0.015902  0.390411    0.390411            0.006208   \n",
       "6        159  0.017318  0.333333    0.333333            0.005773   \n",
       "7        146  0.015902  0.643836    0.356164            0.005664   \n",
       "8        136  0.014813  0.683824    0.316176            0.004684   \n",
       "9         95  0.010347  0.442105    0.442105            0.004575   \n",
       "10        85  0.009258  0.470588    0.470588            0.004357   \n",
       "11        96  0.010456  0.604167    0.395833            0.004139   \n",
       "12        84  0.009149  0.547619    0.452381            0.004139   \n",
       "13       116  0.012635  0.706897    0.293103            0.003703   \n",
       "14        90  0.009803  0.355556    0.355556            0.003485   \n",
       "\n",
       "    CUMULATIVE_ERROR  \n",
       "0           0.016665  \n",
       "1           0.032132  \n",
       "2           0.041390  \n",
       "3           0.049886  \n",
       "4           0.057510  \n",
       "5           0.063719  \n",
       "6           0.069491  \n",
       "7           0.075155  \n",
       "8           0.079839  \n",
       "9           0.084413  \n",
       "10          0.088770  \n",
       "11          0.092909  \n",
       "12          0.097048  \n",
       "13          0.100752  \n",
       "14          0.104237  \n",
       "\n",
       "[15 rows x 34 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
